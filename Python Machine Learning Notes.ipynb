{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes to the book: Python Machine Learning by Sebastian R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the iris dataset\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = iris.data[:, [2,3]]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the standard scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit_transform\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "\n",
    "# Transform our testing\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=0,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate\n",
    "logit = LogisticRegression(C=1000.0, random_state=0)\n",
    "\n",
    "# Fit\n",
    "logit.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.69167017e-11,   6.23180413e-02,   9.37681959e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the probability of being assigned to each class\n",
    "logit.predict_proba(X_test_scaled[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.72717965,  1.51147115])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.4,  0.2],\n",
       "       [ 1.4,  0.2],\n",
       "       [ 1.3,  0.2],\n",
       "       [ 1.5,  0.2],\n",
       "       [ 1.4,  0.2],\n",
       "       [ 1.7,  0.4],\n",
       "       [ 1.4,  0.3],\n",
       "       [ 1.5,  0.2],\n",
       "       [ 1.4,  0.2],\n",
       "       [ 1.5,  0.1],\n",
       "       [ 1.5,  0.2],\n",
       "       [ 1.6,  0.2],\n",
       "       [ 1.4,  0.1],\n",
       "       [ 1.1,  0.1],\n",
       "       [ 1.2,  0.2],\n",
       "       [ 1.5,  0.4],\n",
       "       [ 1.3,  0.4],\n",
       "       [ 1.4,  0.3],\n",
       "       [ 1.7,  0.3],\n",
       "       [ 1.5,  0.3],\n",
       "       [ 1.7,  0.2],\n",
       "       [ 1.5,  0.4],\n",
       "       [ 1. ,  0.2],\n",
       "       [ 1.7,  0.5],\n",
       "       [ 1.9,  0.2],\n",
       "       [ 1.6,  0.2],\n",
       "       [ 1.6,  0.4],\n",
       "       [ 1.5,  0.2],\n",
       "       [ 1.4,  0.2],\n",
       "       [ 1.6,  0.2],\n",
       "       [ 1.6,  0.2],\n",
       "       [ 1.5,  0.4],\n",
       "       [ 1.5,  0.1],\n",
       "       [ 1.4,  0.2],\n",
       "       [ 1.5,  0.1],\n",
       "       [ 1.2,  0.2],\n",
       "       [ 1.3,  0.2],\n",
       "       [ 1.5,  0.1],\n",
       "       [ 1.3,  0.2],\n",
       "       [ 1.5,  0.2],\n",
       "       [ 1.3,  0.3],\n",
       "       [ 1.3,  0.3],\n",
       "       [ 1.3,  0.2],\n",
       "       [ 1.6,  0.6],\n",
       "       [ 1.9,  0.4],\n",
       "       [ 1.4,  0.3],\n",
       "       [ 1.6,  0.2],\n",
       "       [ 1.4,  0.2],\n",
       "       [ 1.5,  0.2],\n",
       "       [ 1.4,  0.2],\n",
       "       [ 4.7,  1.4],\n",
       "       [ 4.5,  1.5],\n",
       "       [ 4.9,  1.5],\n",
       "       [ 4. ,  1.3],\n",
       "       [ 4.6,  1.5],\n",
       "       [ 4.5,  1.3],\n",
       "       [ 4.7,  1.6],\n",
       "       [ 3.3,  1. ],\n",
       "       [ 4.6,  1.3],\n",
       "       [ 3.9,  1.4],\n",
       "       [ 3.5,  1. ],\n",
       "       [ 4.2,  1.5],\n",
       "       [ 4. ,  1. ],\n",
       "       [ 4.7,  1.4],\n",
       "       [ 3.6,  1.3],\n",
       "       [ 4.4,  1.4],\n",
       "       [ 4.5,  1.5],\n",
       "       [ 4.1,  1. ],\n",
       "       [ 4.5,  1.5],\n",
       "       [ 3.9,  1.1],\n",
       "       [ 4.8,  1.8],\n",
       "       [ 4. ,  1.3],\n",
       "       [ 4.9,  1.5],\n",
       "       [ 4.7,  1.2],\n",
       "       [ 4.3,  1.3],\n",
       "       [ 4.4,  1.4],\n",
       "       [ 4.8,  1.4],\n",
       "       [ 5. ,  1.7],\n",
       "       [ 4.5,  1.5],\n",
       "       [ 3.5,  1. ],\n",
       "       [ 3.8,  1.1],\n",
       "       [ 3.7,  1. ],\n",
       "       [ 3.9,  1.2],\n",
       "       [ 5.1,  1.6],\n",
       "       [ 4.5,  1.5],\n",
       "       [ 4.5,  1.6],\n",
       "       [ 4.7,  1.5],\n",
       "       [ 4.4,  1.3],\n",
       "       [ 4.1,  1.3],\n",
       "       [ 4. ,  1.3],\n",
       "       [ 4.4,  1.2],\n",
       "       [ 4.6,  1.4],\n",
       "       [ 4. ,  1.2],\n",
       "       [ 3.3,  1. ],\n",
       "       [ 4.2,  1.3],\n",
       "       [ 4.2,  1.2],\n",
       "       [ 4.2,  1.3],\n",
       "       [ 4.3,  1.3],\n",
       "       [ 3. ,  1.1],\n",
       "       [ 4.1,  1.3],\n",
       "       [ 6. ,  2.5],\n",
       "       [ 5.1,  1.9],\n",
       "       [ 5.9,  2.1],\n",
       "       [ 5.6,  1.8],\n",
       "       [ 5.8,  2.2],\n",
       "       [ 6.6,  2.1],\n",
       "       [ 4.5,  1.7],\n",
       "       [ 6.3,  1.8],\n",
       "       [ 5.8,  1.8],\n",
       "       [ 6.1,  2.5],\n",
       "       [ 5.1,  2. ],\n",
       "       [ 5.3,  1.9],\n",
       "       [ 5.5,  2.1],\n",
       "       [ 5. ,  2. ],\n",
       "       [ 5.1,  2.4],\n",
       "       [ 5.3,  2.3],\n",
       "       [ 5.5,  1.8],\n",
       "       [ 6.7,  2.2],\n",
       "       [ 6.9,  2.3],\n",
       "       [ 5. ,  1.5],\n",
       "       [ 5.7,  2.3],\n",
       "       [ 4.9,  2. ],\n",
       "       [ 6.7,  2. ],\n",
       "       [ 4.9,  1.8],\n",
       "       [ 5.7,  2.1],\n",
       "       [ 6. ,  1.8],\n",
       "       [ 4.8,  1.8],\n",
       "       [ 4.9,  1.8],\n",
       "       [ 5.6,  2.1],\n",
       "       [ 5.8,  1.6],\n",
       "       [ 6.1,  1.9],\n",
       "       [ 6.4,  2. ],\n",
       "       [ 5.6,  2.2],\n",
       "       [ 5.1,  1.5],\n",
       "       [ 5.6,  1.4],\n",
       "       [ 6.1,  2.3],\n",
       "       [ 5.6,  2.4],\n",
       "       [ 5.5,  1.8],\n",
       "       [ 4.8,  1.8],\n",
       "       [ 5.4,  2.1],\n",
       "       [ 5.6,  2.4],\n",
       "       [ 5.1,  2.3],\n",
       "       [ 5.1,  1.9],\n",
       "       [ 5.9,  2.3],\n",
       "       [ 5.7,  2.5],\n",
       "       [ 5.2,  2.3],\n",
       "       [ 5. ,  1.9],\n",
       "       [ 5.2,  2. ],\n",
       "       [ 5.4,  2.3],\n",
       "       [ 5.1,  1.8]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the weights\n",
    "w = np.zeros(1 + X.shape[1])\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Net input function\n",
    "def net_input(X, w):\n",
    "    return np.dot(X, w[1:]) + w[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_input(X, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(net_input(X, w) >= 0, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Data and Feature Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b     c    d\n",
       "0  1   2   3.0  4.0\n",
       "1  5   6   NaN  8.0\n",
       "2  0  11  12.0  NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create some data\n",
    "data = {'a': [1, 5, 0], \n",
    "       'b': [2, 6, 11],\n",
    "       'c':[3, np.nan, 12],\n",
    "       'd': [4, 8, np.nan]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       a      b      c      d\n",
       "0  False  False  False  False\n",
       "1  False  False   True  False\n",
       "2  False  False  False   True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .isnull() method\n",
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    0\n",
       "b    0\n",
       "c    1\n",
       "d    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .isnull().sum() returns number of NaN in each column via Series\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b    c    d\n",
       "0  1  2  3.0  4.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop any row containing NaN via .dropna()\n",
    "df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b\n",
       "0  1   2\n",
       "1  5   6\n",
       "2  0  11"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop any column containing NaN via dropna(axis=1)\n",
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- .dropna() has many parameters:\n",
    "    - how='all' : drops rows where all columns are NaN\n",
    "    - thresh=n  : drop rows that have not at least 4 non-NaN values\n",
    "    - subset=['C'] : drops rows where NaN appears in specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1. ,   2. ,   3. ,   4. ],\n",
       "       [  5. ,   6. ,   7.5,   8. ],\n",
       "       [  0. ,  11. ,  12. ,   6. ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Create the imputer\n",
    "imptr = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "\n",
    "# Fit and transform\n",
    "imptr.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Above, each NaN was replaced by the corresponding mean for each column.\n",
    "- If axis=1, then it calculates on a row by row basis.\n",
    "- axis=0 calculates on a column basis.\n",
    "- Other strategy= params:\n",
    "    - 'median', 'most_frequent'\n",
    "- 'most_frequent' most useful for imputing categorical feature values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Dealing w/ Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>label</th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>A</td>\n",
       "      <td>10.10</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>B</td>\n",
       "      <td>13.50</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>A</td>\n",
       "      <td>21.99</td>\n",
       "      <td>XL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color label  price size\n",
       "0  green     A  10.10    M\n",
       "1    red     B  13.50    L\n",
       "2   blue     A  21.99   XL"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new data\n",
    "data_2 = {'color': ['green', 'red', 'blue'],\n",
    "         'size': ['M', 'L', 'XL'],\n",
    "         'price': [10.1, 13.5, 21.99],\n",
    "         'label': ['A', 'B', 'A']}\n",
    "\n",
    "df2 = pd.DataFrame(data_2)\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the ordinal features into integers for analysis.\n",
    "- Ordinal Features are categorical features w/ values that could/can be logically sorted; they could have some implicit ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>label</th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>A</td>\n",
       "      <td>10.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>B</td>\n",
       "      <td>13.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>A</td>\n",
       "      <td>21.99</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color label  price  size\n",
       "0  green     A  10.10     1\n",
       "1    red     B  13.50     2\n",
       "2   blue     A  21.99     3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the size mapping\n",
    "size_mapping = {'XL': 3, 'L': 2, 'M': 1}\n",
    "\n",
    "# Map\n",
    "df2.size = df2['size'].map(size_mapping)\n",
    "\n",
    "# Show\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0, 'B': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the class mapping; starts at 0\n",
    "class_mapping = {label:idx for idx, label in enumerate(np.unique(df2.label))}\n",
    "\n",
    "class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>label</th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>0</td>\n",
       "      <td>10.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>1</td>\n",
       "      <td>13.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>0</td>\n",
       "      <td>21.99</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  label  price  size\n",
       "0  green      0  10.10     1\n",
       "1    red      1  13.50     2\n",
       "2   blue      0  21.99     3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.label = df2.label.map(class_mapping)\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Series.map?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding\n",
    "- Used for nominal feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.  ,   1.  ,   0.  ,   1.  ,  10.1 ],\n",
       "       [  0.  ,   0.  ,   1.  ,   2.  ,  13.5 ],\n",
       "       [  1.  ,   0.  ,   0.  ,   3.  ,  21.99]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we must label encode\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "X = df2[['color','size','price']].values\n",
    "X[:, 0] = label_encoder.fit_transform(X[:,0])\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Instantiate\n",
    "one_hot = OneHotEncoder(categorical_features=[0])\n",
    "\n",
    "# Fit transform\n",
    "one_hot.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "      <th>color_blue</th>\n",
       "      <th>color_green</th>\n",
       "      <th>color_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.50</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.99</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  size  color_blue  color_green  color_red\n",
       "0  10.10     1           0            1          0\n",
       "1  13.50     2           0            0          1\n",
       "2  21.99     3           1            0          0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way:\n",
    "pd.get_dummies(df2[['price', 'color', 'size']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "      <th>color_blue</th>\n",
       "      <th>color_green</th>\n",
       "      <th>color_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.50</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>21.99</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  price  size  color_blue  color_green  color_red\n",
       "0      0  10.10     1           0            1          0\n",
       "1      1  13.50     2           0            0          1\n",
       "2      0  21.99     3           1            0          0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Analyzing the Wine dataset from UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
       "0   1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
       "1   1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "2   1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
       "3   1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
       "4   1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
       "\n",
       "     13  \n",
       "0  1065  \n",
       "1  1050  \n",
       "2  1185  \n",
       "3  1480  \n",
       "4   735  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "wine = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\",\n",
    "                  header=None)\n",
    "\n",
    "# Check our work\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "wine.columns = ['label', 'alcohol', 'malic_acid', 'ash', 'ash_alcalinity', 'magnesium', 'phenols',\n",
    "               'flavonoids', 'nonflav_phenols', 'proanthos', 'color_intensity', 'hue', 'od_nbrs',\n",
    "               'proline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>ash_alcalinity</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>phenols</th>\n",
       "      <th>flavonoids</th>\n",
       "      <th>nonflav_phenols</th>\n",
       "      <th>proanthos</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od_nbrs</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  alcohol  malic_acid   ash  ash_alcalinity  magnesium  phenols  \\\n",
       "0      1    14.23        1.71  2.43            15.6        127     2.80   \n",
       "1      1    13.20        1.78  2.14            11.2        100     2.65   \n",
       "2      1    13.16        2.36  2.67            18.6        101     2.80   \n",
       "3      1    14.37        1.95  2.50            16.8        113     3.85   \n",
       "4      1    13.24        2.59  2.87            21.0        118     2.80   \n",
       "\n",
       "   flavonoids  nonflav_phenols  proanthos  color_intensity   hue  od_nbrs  \\\n",
       "0        3.06             0.28       2.29             5.64  1.04     3.92   \n",
       "1        2.76             0.26       1.28             4.38  1.05     3.40   \n",
       "2        3.24             0.30       2.81             5.68  1.03     3.17   \n",
       "3        3.49             0.24       2.18             7.80  0.86     3.45   \n",
       "4        2.69             0.39       1.82             4.32  1.04     2.93   \n",
       "\n",
       "   proline  \n",
       "0     1065  \n",
       "1     1050  \n",
       "2     1185  \n",
       "3     1480  \n",
       "4      735  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class labels\n",
    "np.unique(wine.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.398876\n",
       "1    0.331461\n",
       "3    0.269663\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.label.value_counts(dropna=False, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(wine.iloc[:, 1:].values, wine.iloc[:, 0].values,\n",
    "                                                   test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature scaling\n",
    "- Normalization: puts our data onto a scale from [0, 1]\n",
    "- Standardization: centers our data w/ mean 0 and standard deviation 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "# Scale our data\n",
    "# Load the needed packages\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Instantiate\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "# Fit and transform training\n",
    "X_train_norm = mms.fit_transform(X_train)\n",
    "\n",
    "# Transform our test data\n",
    "X_test_norm = mms.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ssc = StandardScaler()\n",
    "\n",
    "# Fit and transform\n",
    "X_train_std = ssc.fit_transform(X_train)\n",
    "\n",
    "# Transform test data\n",
    "X_test_std = ssc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy 0.984\n",
      "Test accuracy 0.981\n"
     ]
    }
   ],
   "source": [
    "# Accuracy metrics / evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a logistic model\n",
    "lr = LogisticRegression(penalty='l1', C=0.1)\n",
    "\n",
    "# Fit\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "# Show accuracy\n",
    "print(\"Training accuracy {:.3f}\".format(lr.score(X_train_std, y_train)))\n",
    "print(\"Test accuracy {:.3f}\".format(accuracy_score(y_test, lr.predict(X_test_std))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the train and test are approx equal => no overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.38380621, -0.15809157, -0.70037112])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used the One-vs-Rest approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28000925,  0.        ,  0.        , -0.0278746 ,  0.        ,\n",
       "         0.        ,  0.70997992,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.23653736],\n",
       "       [-0.64393599, -0.06882938, -0.05719789,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -0.9268855 ,\n",
       "         0.0600909 ,  0.        , -0.37100969],\n",
       "       [ 0.        ,  0.06140666,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.63682779,  0.        ,  0.        ,  0.49844875,\n",
       "        -0.35812725, -0.57054435,  0.        ]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3 rows of weight coefs; one weight vector for each class. \n",
    "- each row consists of 13 weights, where each weight is multiplied by the respective feature in the 13-D dataset to calculate the net-input z."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can assess feature importance w/ random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 alcohol - 0.18248261633081447\n",
      "2 malic_acid - 0.15860977439208598\n",
      "3 ash - 0.15094794797803848\n",
      "4 ash_alcalinity - 0.13198679742764774\n",
      "5 magnesium - 0.1065890612251934\n",
      "6 phenols - 0.07824278809689261\n",
      "7 flavonoids - 0.060717598651490616\n",
      "8 nonflav_phenols - 0.032033191209174174\n",
      "9 proanthos - 0.025399678325383392\n",
      "10 color_intensity - 0.022351122470445416\n",
      "11 hue - 0.02207807404077184\n",
      "12 od_nbrs - 0.014645160876579336\n",
      "13 proline - 0.013916188975481122\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Get the columns\n",
    "cols = wine.columns[1:]\n",
    "\n",
    "# Make the forest\n",
    "forest = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Fit\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "# Get the importances\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "# Get the indices\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Show the importance of each feature\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"{} - {}\".format(cols[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 12,  6, 11,  0, 10,  5,  3,  1,  8,  4,  7,  2])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>ash_alcalinity</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>phenols</th>\n",
       "      <th>flavonoids</th>\n",
       "      <th>nonflav_phenols</th>\n",
       "      <th>proanthos</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od_nbrs</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  alcohol  malic_acid   ash  ash_alcalinity  magnesium  phenols  \\\n",
       "0      1    14.23        1.71  2.43            15.6        127     2.80   \n",
       "1      1    13.20        1.78  2.14            11.2        100     2.65   \n",
       "2      1    13.16        2.36  2.67            18.6        101     2.80   \n",
       "3      1    14.37        1.95  2.50            16.8        113     3.85   \n",
       "4      1    13.24        2.59  2.87            21.0        118     2.80   \n",
       "\n",
       "   flavonoids  nonflav_phenols  proanthos  color_intensity   hue  od_nbrs  \\\n",
       "0        3.06             0.28       2.29             5.64  1.04     3.92   \n",
       "1        2.76             0.26       1.28             4.38  1.05     3.40   \n",
       "2        3.24             0.30       2.81             5.68  1.03     3.17   \n",
       "3        3.49             0.24       2.18             7.80  0.86     3.45   \n",
       "4        2.69             0.39       1.82             4.32  1.04     2.93   \n",
       "\n",
       "   proline  \n",
       "0     1065  \n",
       "1     1050  \n",
       "2     1185  \n",
       "3     1480  \n",
       "4      735  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label              0\n",
       "alcohol            0\n",
       "malic_acid         0\n",
       "ash                0\n",
       "ash_alcalinity     0\n",
       "magnesium          0\n",
       "phenols            0\n",
       "flavonoids         0\n",
       "nonflav_phenols    0\n",
       "proanthos          0\n",
       "color_intensity    0\n",
       "hue                0\n",
       "od_nbrs            0\n",
       "proline            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    13.744746\n",
       "2    12.278732\n",
       "3    13.153750\n",
       "Name: alcohol, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.groupby(['label'])['alcohol'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- PCA provides unsupervised data compression; it's an unsupervised linear transformation for dimensionality reduction.\n",
    "    - PCA finds the directions of maximum variance in the dataset and projects it onto a new subspace w/ fewer dimensions than the original dataset.\n",
    "    - The pricinpal components are the eigenvectors; the ones selected are the ones w/ the most information/variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "PCA Algorithm steps:\n",
    "- 1): Standardize the m-dimensional dataset\n",
    "- 2): Construct the covariance matrix\n",
    "- 3): Decompose covariance matrix into its eigenvectors (principal component) and eigenvalues\n",
    "- 4): Select k largest eigenvalues; k represents the dimensionality of the new dataset.\n",
    "- 5): Construct a projection matrix W from the top k eigenvalues\n",
    "- 6): Transform the m-dimensional dataset using W to obtain a new k-dimensional dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's analyze the wine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>ash_alcalinity</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>phenols</th>\n",
       "      <th>flavonoids</th>\n",
       "      <th>nonflav_phenols</th>\n",
       "      <th>proanthos</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od_nbrs</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  alcohol  malic_acid   ash  ash_alcalinity  magnesium  phenols  \\\n",
       "0      1    14.23        1.71  2.43            15.6        127     2.80   \n",
       "1      1    13.20        1.78  2.14            11.2        100     2.65   \n",
       "2      1    13.16        2.36  2.67            18.6        101     2.80   \n",
       "3      1    14.37        1.95  2.50            16.8        113     3.85   \n",
       "4      1    13.24        2.59  2.87            21.0        118     2.80   \n",
       "\n",
       "   flavonoids  nonflav_phenols  proanthos  color_intensity   hue  od_nbrs  \\\n",
       "0        3.06             0.28       2.29             5.64  1.04     3.92   \n",
       "1        2.76             0.26       1.28             4.38  1.05     3.40   \n",
       "2        3.24             0.30       2.81             5.68  1.03     3.17   \n",
       "3        3.49             0.24       2.18             7.80  0.86     3.45   \n",
       "4        2.69             0.39       1.82             4.32  1.04     2.93   \n",
       "\n",
       "   proline  \n",
       "0     1065  \n",
       "1     1050  \n",
       "2     1185  \n",
       "3     1480  \n",
       "4      735  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the data, then split into training and testing\n",
    "X, y = wine.iloc[:, 1:], wine.iloc[:, 0]\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "sc_2 = StandardScaler()\n",
    "\n",
    "# Fit_transform\n",
    "X_train_scale = sc_2.fit_transform(X_train)\n",
    "\n",
    "# do the same w/ test\n",
    "X_test_scale = sc_2.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Construct the covariance matrix:\n",
    "- Positive covariance => the random vars vary together in the same direction\n",
    "- Negative covariance => the random vars vary in *opposite* directions\n",
    "\n",
    "The eigenvectors of the covariance matrix are the principal components; the directions of maximum variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eigenvalues\n",
      " [ 4.8923083   2.46635032  1.42809973  1.01233462  0.84906459  0.60181514\n",
      "  0.52251546  0.08414846  0.33051429  0.29595018  0.16831254  0.21432212\n",
      "  0.2399553 ]\n"
     ]
    }
   ],
   "source": [
    "# Construct covariance matrix\n",
    "cov_matrix = np.cov(X_train_scale.T)\n",
    "\n",
    "# Get the eigenvalues and eigenvectors\n",
    "eigen_vals, eigen_vectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "print(\"\\nEigenvalues\\n {}\".format(eigen_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the eigenpairs\n",
    "eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vectors[:, i]) for i in range (len(eigen_vals))]\n",
    "eigen_pairs.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the projection matrix\n",
    "W = np.hstack((eigen_pairs[0][1][:, np.newaxis], eigen_pairs[1][1][:, np.newaxis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform our data\n",
    "X_train_pca = X_train_scale.dot(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.59891628,  0.00484089],\n",
       "       [ 0.15819134, -2.26659577],\n",
       "       [-2.6372337 ,  2.66488569],\n",
       "       [-2.52848449,  0.51846618],\n",
       "       [ 1.70922581, -0.91719459],\n",
       "       [-2.83057003,  0.41936129],\n",
       "       [-2.82251879,  1.99763147],\n",
       "       [ 1.36618015,  0.04639099],\n",
       "       [-2.46584868, -0.07932269],\n",
       "       [-2.28554906, -0.40096658],\n",
       "       [ 1.14246632, -2.39587633],\n",
       "       [-2.28497881, -1.09274988],\n",
       "       [-2.52924945,  0.6477328 ],\n",
       "       [ 0.169245  , -1.1264982 ],\n",
       "       [ 2.53088166,  1.05798498],\n",
       "       [-0.71596964, -2.80365836],\n",
       "       [ 2.46922033, -0.15871191],\n",
       "       [-0.58044574, -0.69290749],\n",
       "       [ 0.54583852,  0.41042188],\n",
       "       [ 3.5604963 ,  1.42561284],\n",
       "       [ 1.58679826, -1.51260121],\n",
       "       [ 2.54872139, -0.05280515],\n",
       "       [-3.59338727,  0.88321901],\n",
       "       [-1.60406659,  2.40373662],\n",
       "       [ 1.48668426, -1.40863724],\n",
       "       [ 0.00830468, -2.04898307],\n",
       "       [-0.15646658, -2.80278355],\n",
       "       [-2.39863877,  2.47524175],\n",
       "       [-3.13549157, -0.29421321],\n",
       "       [ 3.30221023,  0.40939296],\n",
       "       [-3.53069904,  1.79971521],\n",
       "       [-0.45566459, -2.61242833],\n",
       "       [-0.58840115, -1.98301934],\n",
       "       [-1.16637216, -0.83784744],\n",
       "       [ 1.03763587, -1.37755233],\n",
       "       [ 1.95890184, -1.62578024],\n",
       "       [ 2.76990407,  1.86073384],\n",
       "       [ 2.06150478,  1.32280528],\n",
       "       [ 0.84107017, -2.00894711],\n",
       "       [ 3.52522122,  1.41880443],\n",
       "       [-3.82504747,  0.11741931],\n",
       "       [ 1.70427554, -0.46267479],\n",
       "       [-3.44482795,  0.89793105],\n",
       "       [ 3.14119715,  0.80251074],\n",
       "       [ 2.34148171,  1.69991384],\n",
       "       [ 1.25162098, -0.91305357],\n",
       "       [ 3.57847538,  1.78146353],\n",
       "       [ 0.93052986, -2.26747372],\n",
       "       [ 0.50457042, -1.9619121 ],\n",
       "       [ 3.82251943,  2.88150786],\n",
       "       [-2.3761711 ,  2.15480504],\n",
       "       [-1.55524357, -1.38425679],\n",
       "       [ 2.51130377,  1.33358811],\n",
       "       [-0.72998664, -0.21814915],\n",
       "       [-0.77183165, -2.39360847],\n",
       "       [ 0.84583296, -1.51455514],\n",
       "       [-1.26515775,  0.04977931],\n",
       "       [ 2.20903303,  0.85715074],\n",
       "       [-3.89082853,  0.54194575],\n",
       "       [-1.8063292 ,  1.31606219],\n",
       "       [ 4.37183355,  2.33594051],\n",
       "       [ 3.31126031,  1.43233851],\n",
       "       [-1.53830238, -1.9287237 ],\n",
       "       [-2.72256164,  2.15319971],\n",
       "       [ 2.81726412,  1.3810016 ],\n",
       "       [ 1.85165682,  0.74908527],\n",
       "       [-0.45023913, -2.16233055],\n",
       "       [-0.10551849, -1.20083745],\n",
       "       [ 1.96348867,  0.21556727],\n",
       "       [ 2.23499535,  1.29680173],\n",
       "       [ 0.81061036,  0.32968368],\n",
       "       [-3.28947263,  2.24576835],\n",
       "       [ 0.92542109, -0.76230572],\n",
       "       [ 2.3186051 , -0.12948205],\n",
       "       [ 0.79856144, -1.42131736],\n",
       "       [-2.27737367,  0.55018386],\n",
       "       [ 3.14731552,  1.31152545],\n",
       "       [-1.73268901, -1.77855936],\n",
       "       [-2.85178367,  0.15732478],\n",
       "       [-2.682777  ,  0.33277815],\n",
       "       [ 1.93435789,  1.6156844 ],\n",
       "       [ 1.61938048, -0.63200211],\n",
       "       [-2.04371299,  0.31389153],\n",
       "       [ 2.25520575,  1.89312658],\n",
       "       [-2.32821566,  0.18612349],\n",
       "       [-0.41435801, -1.98875351],\n",
       "       [ 1.44705447,  0.66672748],\n",
       "       [ 2.19851825,  0.68997732],\n",
       "       [-0.42257991, -1.94397583],\n",
       "       [ 2.76213322,  1.54543423],\n",
       "       [-2.84540302,  1.94250398],\n",
       "       [-1.5915982 , -1.41522865],\n",
       "       [-3.35600644,  1.14127988],\n",
       "       [ 1.67829924,  0.10816612],\n",
       "       [-2.94150833,  0.3885073 ],\n",
       "       [-2.30405629,  2.15027517],\n",
       "       [-3.49291623,  1.29239829],\n",
       "       [ 2.33527547,  0.3435751 ],\n",
       "       [ 1.46219731, -2.05255915],\n",
       "       [-0.43118871, -2.4048574 ],\n",
       "       [ 0.42256584, -1.05544618],\n",
       "       [ 0.52658784, -3.87214144],\n",
       "       [-2.72797263,  1.58306403],\n",
       "       [-3.17868679,  2.71193573],\n",
       "       [-0.62158919, -1.0446325 ],\n",
       "       [-1.40436141, -1.47634167],\n",
       "       [ 0.91169846,  0.65475647],\n",
       "       [ 1.12423581, -1.34653907],\n",
       "       [-2.84547545,  1.32732299],\n",
       "       [-2.36335963,  2.43164111],\n",
       "       [ 2.54578547,  1.85201533],\n",
       "       [ 3.21543609,  1.84137496],\n",
       "       [-2.74703277,  0.19539224],\n",
       "       [-1.05186423, -1.83455849],\n",
       "       [-1.50826783, -0.99164925],\n",
       "       [-0.53471293, -2.50577398],\n",
       "       [ 1.40057023,  0.66105221],\n",
       "       [ 1.10794215,  0.24580628],\n",
       "       [ 2.83487283,  0.95812357],\n",
       "       [-0.52771371, -2.59472825],\n",
       "       [ 0.31128129, -2.28677331],\n",
       "       [-0.06526682, -2.04360861],\n",
       "       [ 2.91835495,  0.82035658],\n",
       "       [-2.40719925,  2.23612256]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement PCA in scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Instantiate\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Fit_transform\n",
    "X_train_pca = pca.fit_transform(X_train_scale)\n",
    "\n",
    "# Transform test\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35185185185185186"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create logistic regression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Fit\n",
    "lr.fit(X_train_pca, y_train)\n",
    "\n",
    "# Score\n",
    "accuracy_score(y_test, lr.predict(X_test_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation & Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Pipelines in sci-kit learn := a method to fit a model with an arbitrary number of transformation steps, and apply it to make predictions about new data.\n",
    "- Pipelines let one seamlessly chain feature scaling, feature selection, and modelling into one method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data; Wisconsin breast cancer dataset\n",
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>842302</th>\n",
       "      <th>M</th>\n",
       "      <th>17.99</th>\n",
       "      <th>10.38</th>\n",
       "      <th>122.8</th>\n",
       "      <th>1001</th>\n",
       "      <th>0.1184</th>\n",
       "      <th>0.2776</th>\n",
       "      <th>0.3001</th>\n",
       "      <th>0.1471</th>\n",
       "      <th>...</th>\n",
       "      <th>25.38</th>\n",
       "      <th>17.33</th>\n",
       "      <th>184.6</th>\n",
       "      <th>2019</th>\n",
       "      <th>0.1622</th>\n",
       "      <th>0.6656</th>\n",
       "      <th>0.7119</th>\n",
       "      <th>0.2654</th>\n",
       "      <th>0.4601</th>\n",
       "      <th>0.1189</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.1578</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     842302  M  17.99  10.38   122.8    1001   0.1184   0.2776  0.3001  \\\n",
       "0    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "1  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "2  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "3  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "4    843786  M  12.45  15.70   82.57   477.1  0.12780  0.17000  0.1578   \n",
       "\n",
       "    0.1471   ...     25.38  17.33   184.6    2019  0.1622  0.6656  0.7119  \\\n",
       "0  0.07017   ...     24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416   \n",
       "1  0.12790   ...     23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504   \n",
       "2  0.10520   ...     14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869   \n",
       "3  0.10430   ...     22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000   \n",
       "4  0.08089   ...     15.47  23.75  103.40   741.6  0.1791  0.5249  0.5355   \n",
       "\n",
       "   0.2654  0.4601   0.1189  \n",
       "0  0.1860  0.2750  0.08902  \n",
       "1  0.2430  0.3613  0.08758  \n",
       "2  0.2575  0.6638  0.17300  \n",
       "3  0.1625  0.2364  0.07678  \n",
       "4  0.1741  0.3985  0.12440  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the outcome column w/ numerical data (it's nominal)\n",
    "def label_mapping(val):\n",
    "    if val == \"M\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    211\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.M.map(label_mapping)\n",
    "df.label.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop column M\n",
    "df = df.drop(\"M\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>842302</th>\n",
       "      <th>17.99</th>\n",
       "      <th>10.38</th>\n",
       "      <th>122.8</th>\n",
       "      <th>1001</th>\n",
       "      <th>0.1184</th>\n",
       "      <th>0.2776</th>\n",
       "      <th>0.3001</th>\n",
       "      <th>0.1471</th>\n",
       "      <th>0.2419</th>\n",
       "      <th>...</th>\n",
       "      <th>17.33</th>\n",
       "      <th>184.6</th>\n",
       "      <th>2019</th>\n",
       "      <th>0.1622</th>\n",
       "      <th>0.6656</th>\n",
       "      <th>0.7119</th>\n",
       "      <th>0.2654</th>\n",
       "      <th>0.4601</th>\n",
       "      <th>0.1189</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842517</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84300903</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84348301</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84358402</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>843786</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.1578</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     842302  17.99  10.38   122.8    1001   0.1184   0.2776  0.3001   0.1471  \\\n",
       "0    842517  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017   \n",
       "1  84300903  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790   \n",
       "2  84348301  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520   \n",
       "3  84358402  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430   \n",
       "4    843786  12.45  15.70   82.57   477.1  0.12780  0.17000  0.1578  0.08089   \n",
       "\n",
       "   0.2419  ...    17.33   184.6    2019  0.1622  0.6656  0.7119  0.2654  \\\n",
       "0  0.1812  ...    23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "1  0.2069  ...    25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "2  0.2597  ...    26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "3  0.1809  ...    16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "4  0.2087  ...    23.75  103.40   741.6  0.1791  0.5249  0.5355  0.1741   \n",
       "\n",
       "   0.4601   0.1189  label  \n",
       "0  0.2750  0.08902      0  \n",
       "1  0.3613  0.08758      0  \n",
       "2  0.6638  0.17300      0  \n",
       "3  0.2364  0.07678      0  \n",
       "4  0.3985  0.12440      0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the features\n",
    "X = df.iloc[:, :-1].values\n",
    "\n",
    "# Get the labels\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put the data into a Pipeline\n",
    "# Load the needed models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "pipeline_logit = Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components=2)),\n",
    "                          ('logit', LogisticRegression(random_state=1, C=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, n_components=2, whiten=False)), ('logit', LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline\n",
    "pipeline_logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.956\n"
     ]
    }
   ],
   "source": [
    "# Predit and score\n",
    "print(\"Test accuracy: {:.3f}\".format(pipeline_logit.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline takes a list of tuples; first tuple element is a string identifier, second tuple element is a sci-kit learn transformer or estimator (model).\n",
    "- First step(s) transform the data\n",
    "- The last step is a model/estimator\n",
    "- There is no limit to the number of intermediate steps before the estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Model selection* := the process of selecting and comparing different hyperparameter values to improve prediction performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation (CV) techniques\n",
    "- Used to assess model generalization performance\n",
    "- Helps find bias-variance trade-off\n",
    "- There are various CV techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Holdout method for cross-validation*\n",
    "- Seperate the data into: training set, validation set, and test set.\n",
    "    - Train set used to fit different models\n",
    "    - Validation set performance is used for model selection; repeatedly evaluate the model performace using various parameter values\n",
    "    - The test set provides a less biased estimate of model's ability to generalize\n",
    "\n",
    "- Disadvantage: model will be sensitive to how the data is partitioned into train and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*K-Fold cross-validation*\n",
    "\n",
    "- Randomly split the training dataset into k folds w/out replacement, where k-1 folds are used for model training and one fold used for testing.\n",
    "    - This is repeated k times; results in k models and performance estimates.\n",
    "- Then we find optimal hyperparameter values, then train the model on complete training set and obtain a final performance estimate on the test set.\n",
    "- Standard k value: 10;\n",
    "    - working w/ small train sets, use higher k\n",
    "    - working w/ larger train sets, use lower k; 5\n",
    "\n",
    "*Leave-One-Out Cross-Validation*\n",
    "\n",
    "- Used for very small data sets\n",
    "- Set the number of folds k = n samples; one training sample is used for testing during each iteration.\n",
    "\n",
    "*Stratified K-fold cross-validation*\n",
    "- Used in unequal class distribution situations\n",
    "- Class proportions are preserved in each fold; this ensures that each fold is representative of the class proportions in the training set.\n",
    "- More robust than Standard K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement Stratified k-fold CV\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create folds\n",
    "k_fold = StratifiedKFold(y=y_train, n_folds=10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list to hold the scores\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k, (train, test) in enumerate(k_fold):\n",
    "    pipeline_logit.fit(X_train[train], y_train[train])\n",
    "    score = pipeline_logit.score(X_train[test], y_train[test])\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy: 0.965 +/- 0.026\n"
     ]
    }
   ],
   "source": [
    "print(\"CV accuracy: {:.3f} +/- {:.3f}\".format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can do the same above via sci-kit learn; uses Stratified K-Fold CV\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# Create scores; returns cv scores\n",
    "scores = cross_val_score(estimator=pipeline_logit, X=X_train, y=y_train, cv=10, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.93478261,  0.93478261,  0.95652174,  1.        ,\n",
       "        0.93478261,  1.        ,  0.97727273,  0.95454545,  0.95454545])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy of the 10 models is 0.965 w/ +/- 0.026 std.\n"
     ]
    }
   ],
   "source": [
    "# Same as above\n",
    "print(\"The mean accuracy of the 10 models is {:.3f} w/ +/- {:.3f} std.\".format(np.mean(scores),\n",
    "                                                                              np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using cross_val_score's n_jobs parameter, we can distribute the CVs to various CPUs available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning and Validation Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.learning_curve import learning_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a Pipeline object\n",
    "pipe_lr = Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(penalty='l2',\n",
    "                                                                            random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use the learning_curve function\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=pipe_lr, X=X_train, y=y_train,\n",
    "                                                       train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                                                       cv=10, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate training mean\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "\n",
    "# Calculate training standard deviation\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Calculate test mean and standard deviation\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIgiCIKhLdBZBEARBXf4PJ4eShgH8dH4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cf5b240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5,\n",
    "         label='training accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15,\n",
    "                color='blue')\n",
    "\n",
    "plt.plot(train_sizes,test_mean, linestyle='--', color='green', marker='s', markersize=5,\n",
    "        label='validation accuracy')\n",
    "plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15,\n",
    "                 color='green')\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.8, 1.05])\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import needed function\n",
    "from sklearn.learning_curve import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create parameter range\n",
    "param_vals = [0.001, 0.01, 0.1, 1.0, 10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call the function\n",
    "train_scores, test_scores = validation_curve(estimator=pipe_lr, X=X_train, y=y_train, \n",
    "                                            param_name='clf__C',\n",
    "                                            param_range=param_vals, cv=10)\n",
    "\n",
    "# Calculate training mean\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "\n",
    "# Calculate training standard deviation\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Calculate test mean and standard deviation\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEaCAYAAAA7YdFPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wfHbqX7BZz0DQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c3282b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "plt.plot(param_vals, train_mean, color='blue', marker='o', markersize=5,\n",
    "         label='training accuracy')\n",
    "\n",
    "plt.fill_between(param_vals, train_mean + train_std, train_mean - train_std, alpha=0.15,\n",
    "                color='blue')\n",
    "\n",
    "plt.plot(param_vals, test_mean, linestyle='--', color='green', marker='s', markersize=5,\n",
    "        label='validation accuracy')\n",
    "\n",
    "plt.fill_between(param_vals, test_mean + test_std, test_mean - test_std, alpha=0.15,\n",
    "                 color='green')\n",
    "plt.grid()\n",
    "plt.xscale('log')\n",
    "plt.xlabel('C Parameter')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.8, 1.0])\n",
    "plt.title(\"Validation Curve\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning via Grid-Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid-search := method used to find the optimal combination of values for each hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the GridSearchCV class\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Pipeline object\n",
    "pipe_svc = Pipeline([('scl', StandardScaler()), ('clf', SVC(random_state=1))])\n",
    "\n",
    "# Create a parameter range to search\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10, 100, 1000]\n",
    "\n",
    "# Create a parameter grid\n",
    "param_grid = [{'clf__C': param_range, 'clf__kernel':['linear']}, {'clf__C': param_range,\n",
    "                                                                 'clf__gamma': param_range,\n",
    "                                                                 'clf__kernel': ['rbf']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=pipe_svc, param_grid=param_grid, scoring='accuracy',\n",
    "                          cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'clf__C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10, 100, 1000], 'clf__kernel': ['linear']}, {'clf__C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10, 100, 1000], 'clf__kernel': ['rbf'], 'clf__gamma': [0.0001, 0.001, 0.01, 0.1, 1.0, 10, 100, 1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.971. With params {'clf__C': 0.1, 'clf__kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Get the score and best parameters\n",
    "print(\"Best score: {:.3f}. With params {}\".format(grid_search.best_score_, grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.982\n"
     ]
    }
   ],
   "source": [
    "# Use the best model and apply it to our test data\n",
    "clf = grid_search.best_estimator_\n",
    "\n",
    "# Fit\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Score our accuracy\n",
    "print(\"Test accuracy: {:.3f}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Perform Nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy: 0.974\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search\n",
    "gs = GridSearchCV(estimator=pipe_svc, param_grid=param_grid, scoring='accuracy', cv=10,\n",
    "                 n_jobs=-1)\n",
    "\n",
    "# Perfom CV using the GridSearchCV object\n",
    "scores = cross_val_score(gs, X_train, y_train, scoring='accuracy', cv=5)\n",
    "\n",
    "print(\"CV accuracy: {:.3f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
